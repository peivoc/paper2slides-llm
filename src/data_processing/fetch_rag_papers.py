import os
import arxiv

def fetch_and_save(query=None, max_results=5, output_dir="data/raw"):
    """
    çˆ¬å–RAGç›¸é—œè«–æ–‡
    """
    os.makedirs(output_dir, exist_ok=True)
    client = arxiv.Client()
    
    # æ”¹é€²çš„æœå°‹æŸ¥è©¢ï¼Œæ›´ç²¾ç¢ºåœ°å®šä½RAGç›¸é—œè«–æ–‡
    if query is None:
        # ä½¿ç”¨æ›´ç²¾ç¢ºçš„æœå°‹ç­–ç•¥
        query = '(ti:"Retrieval-Augmented Generation" OR ti:"Retrieval Augmented Generation" OR ti:RAG) OR (abs:"Retrieval-Augmented Generation" OR abs:"Retrieval Augmented Generation")'
    
    search = arxiv.Search(
        query=query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.Relevance,
        sort_order=arxiv.SortOrder.Descending
    )
    
    print(f"ğŸ” æœå°‹æŸ¥è©¢: {query}")
    print(f"ğŸ“Š é æœŸçµæœæ•¸é‡: {max_results}")
    print("-" * 50)
    
    downloaded_count = 0
    for result in client.results(search):
        print(f"ğŸ“„ æ¨™é¡Œ: {result.title}")
        print(f"ğŸ“… ç™¼è¡¨æ—¥æœŸ: {result.published.strftime('%Y-%m-%d')}")
        print(f"ğŸ‘¥ ä½œè€…: {', '.join([author.name for author in result.authors[:3]])}{'...' if len(result.authors) > 3 else ''}")
        print(f"ğŸ”— åˆ†é¡: {', '.join(result.categories)}")
        
        # æª¢æŸ¥æ˜¯å¦çœŸçš„èˆ‡RAGç›¸é—œ
        title_lower = result.title.lower()
        abstract_lower = result.summary.lower()
        rag_keywords = ['retrieval-augmented', 'retrieval augmented', 'rag', 'retrieve', 'generation']
        
        is_rag_related = any(keyword in title_lower or keyword in abstract_lower for keyword in rag_keywords)
        
        if is_rag_related:
            print("âœ… ç¢ºèªç‚ºRAGç›¸é—œè«–æ–‡")
            
            fname = result.get_short_id() + ".pdf"
            out_path = os.path.join(output_dir, fname)
            
            if not os.path.exists(out_path):
                try:
                    result.download_pdf(filename=out_path)
                    print(f"   âœ… å·²ä¸‹è¼‰è‡³ {out_path}")
                    downloaded_count += 1
                except Exception as e:
                    print(f"   âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            else:
                print("   ğŸ” æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰")
                downloaded_count += 1
        else:
            print("âŒ ä¸æ˜¯RAGç›¸é—œè«–æ–‡ï¼Œè·³é")
        
        print("-" * 30)
    
    print(f"\nğŸ“ˆ ç¸½å…±ä¸‹è¼‰äº† {downloaded_count} ç¯‡RAGç›¸é—œè«–æ–‡")

def fetch_rag_papers_advanced(max_results=10, output_dir="data/raw"):
    """
    ä½¿ç”¨å¤šå€‹æœå°‹ç­–ç•¥ä¾†ç²å–æ›´å¤šRAGç›¸é—œè«–æ–‡
    """
    # ä¸åŒçš„æœå°‹ç­–ç•¥
    search_queries = [
        # ç²¾ç¢ºåŒ¹é…æ¨™é¡Œ
        'ti:"Retrieval-Augmented Generation"',
        'ti:"Retrieval Augmented Generation"',
        'ti:"RAG"',
        
        # æ‘˜è¦ä¸­åŒ…å«ç›¸é—œè©å½™
        'abs:"retrieval-augmented generation"',
        'abs:"retrieval augmented generation"',
        
        # ç›¸é—œæŠ€è¡“è©å½™
        'ti:"dense passage retrieval" OR ti:"DPR"',
        'ti:"retrieval-based" AND ti:"generation"',
        'abs:"retrieval-based question answering"',
        
        # ç›¸é—œæ¨¡å‹å’Œæ–¹æ³•
        'ti:"FiD" OR ti:"Fusion-in-Decoder"',
        'ti:"REALM" OR ti:"Retrieval-Enhanced"',
        'ti:"T5" AND abs:"retrieval"'
    ]
    
    print("ğŸš€ é–‹å§‹é€²éšRAGè«–æ–‡æœå°‹...")
    
    for i, query in enumerate(search_queries, 1):
        print(f"\nğŸ” æœå°‹ç­–ç•¥ {i}/{len(search_queries)}: {query}")
        try:
            fetch_and_save(query=query, max_results=max_results//len(search_queries), output_dir=output_dir)
        except Exception as e:
            print(f"âŒ æœå°‹ç­–ç•¥ {i} å¤±æ•—: {e}")

if __name__ == "__main__":
    # é¸æ“‡æœå°‹æ–¹å¼
    print("è«‹é¸æ“‡æœå°‹æ–¹å¼:")
    print("1. åŸºæœ¬æœå°‹ (æ¨è–¦)")
    print("2. é€²éšæœå°‹ (å¤šç­–ç•¥)")
    
    choice = input("è«‹è¼¸å…¥é¸æ“‡ (1 æˆ– 2): ").strip()
    
    if choice == "2":
        fetch_rag_papers_advanced(max_results=20)
    else:
        fetch_and_save(max_results=90)